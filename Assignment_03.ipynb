{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifshakil2267/Cse317-NemericalMethod-ProblemSolvingSheet01/blob/main/Assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA1ULYtBlK8q"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirsazzathossain/CSE317-Lab/blob/autumn_2022/Lab_Assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDO3b6v3lK8r"
      },
      "source": [
        "#### **Wheat Seed Classification**\n",
        "\n",
        "In this assignment, you will use the [Wheat Seed Dataset](https://archive.ics.uci.edu/ml/datasets/seeds) to classify the type of wheat seed based on the measurements of the seed. The dataset contains 7 attributes and 210 instances. The attributes are:\n",
        "\n",
        "1. Area\n",
        "2. Perimeter\n",
        "3. Compactness\n",
        "4. Length of Kernel\n",
        "5. Width of Kernel\n",
        "6. Asymmetry Coefficient\n",
        "7. Length of Kernel Groove\n",
        "\n",
        "Based on the attributes, the dataset contains 3 classes:\n",
        "\n",
        "1. Kama\n",
        "2. Rosa\n",
        "3. Canadian\n",
        "\n",
        "The text file `seeds_dataset.txt` contains the dataset. The first 7 columns are the attributes and the last column is the class label. The class labels are encoded as  1, 2, and 3 for Kama, Rosa, and Canadian, respectively. The goal of this assignment is to build a classifier that can predict the type of wheat seed based on the measurements of the seed. Follow the instructions below to complete the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eersLEFlK8r"
      },
      "source": [
        "#### **Instructions**\n",
        "\n",
        "1. Download the dataset from [Github](https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/mirsazzathossain/CSE317-Lab-Numerical-Methods/blob/main/datasets/seeds_dataset.txt). It should be saved as `seeds_dataset.txt`.\n",
        "2. Upload the dataset to your Google Drive and mount your Google Drive to Colab.\n",
        "3. Read the dataset using numpy's built-in function `np.genfromtxt()`. Pass the following parameters to the function:\n",
        "    - `fname`: The path to the dataset\n",
        "    - `delimiter`: The delimiter used in the dataset to separate the attributes (Hint: Use `'\\t'` as the delimiter)\n",
        "    \n",
        "4. Shuffle the dataset using `np.random.shuffle()`. Pass the following parameters to the function:\n",
        "    - `x`: The dataset\n",
        "5. Split the dataset into features and labels. The first 7 columns of the dataset are the features and the last column is the label. Use numpy's array slicing to split the dataset into features and labels. (Hint: Use `:` to select all the rows and `0:7` to select the first 7 columns for features and `7` to select the last column for labels)\n",
        "6. Split the dataset into training and testing sets. Use numpy's built-in function `np.split()` to split the dataset into training and testing sets. Pass the following parameters to the function:\n",
        "    - `ary`: The dataset\n",
        "    - `indices_or_sections`: The number of instances in the training set (Hint: Use `int(0.8 * len(dataset))` to get the number of instances in the training set)\n",
        "    - `axis`: The axis to split the dataset (Hint: Use `0` to split the dataset along the rows)\n",
        "7. Find the minimum and maximum values of each feature in the training set. Use numpy's built-in function `np.min()` and `np.max()` to find the minimum and maximum values of each feature in the training set. Pass the following parameters to the function:\n",
        "    - `a`: The training set\n",
        "    - `axis`: The axis to find the minimum and maximum values (Hint: Use `0` to find the minimum and maximum values along the columns)\n",
        "8. In this step, you must normalize the training and test sets. Nomalization is an essential part of every machine learning project. It is used to bring all the features to the same scale. If the features are not normalized, the higher-valued features will outnumber the lower-valued ones.\n",
        "\n",
        "    For example, suppose we have a dataset with two features: the number of bedrooms in a house and the size of the garden in square feet and we are trying to forecast the rent of the residence. If the features are not normalized, the feature with higher values will take precedence over the feature with lower values. In this scenario, the garden area has a greater value. As a result, the model will make an attempt to forecast the house's price depending on the size of the garden. As a consequence, the model will be faulty since most individuals will not pay higher rent for more garden area. We need to normalize the features in order to prevent this. Let's look at the following illustration to better comprehend what we have said:\n",
        "    \n",
        "    - House 1: 2 bedrooms, 2500 sq. ft. garden\n",
        "    - House 2: 3 bedrooms, 500 sq. ft. garden\n",
        "    - House 3: 7 bedrooms, 2300 sq. ft. garden\n",
        "\n",
        "    Considering that most people won't pay more for a larger garden, it follows that the rent for House 1 should be more comparable to House 2 than to House 3. However, if we give the aforementioned data to a k-NN classifier without normalization, it will compute the euclidean distance between the test and training examples and pick the class of the test instance based on the class of the closest training instance.\n",
        "\n",
        "    The euclidean distance between the test instance and the training instances will be:\n",
        "\n",
        "    - Distance between house 1 and house 2: $\\sqrt{(2-3)^2 + (2500-500)^2} = 2000$\n",
        "    - Distance between house 1 and house 3: $\\sqrt{(2-7)^2 + (2500-2300)^2} = 200$\n",
        "\n",
        "    As you can see, the distance between houses 1 and 3 is shorter than that between houses 1 and 2. As a result, the model will forecast that house 1 will cost around the same as house 3. This is not what was anticipated. We need to normalize the features in order to prevent this. To normalize the features, subtract the minimum value of each feature from all the values of that feature and divide the result by the range of the feature. The range of a feature is the difference between the maximum and minimum values of that feature. The formula for normalization is given below:\n",
        "\n",
        "    $$x_{normalized} = \\frac{x - min(x)}{max(x) - min(x)}$$\n",
        "\n",
        "    where $x$ is the feature vector. The above formula will normalize the features to a scale of 0 to 1.\n",
        "\n",
        "    Let's normalize the features in the above example. To do so, we need to find the minimum and maximum values of each feature. The minimum and maximum values of the number of bedrooms are 2 and 7, respectively. The minimum and maximum values of the garden area are 500 and 2500, respectively. The normalized values of the features are given below:\n",
        "\n",
        "    - House 1: $(2 - 2) / 5 = 0$ bedrooms, $(2500 - 500) / 2000 = 0.75$ sq. ft. garden\n",
        "    - House 2: $(3 - 2) / 5 = 0.2$ bedrooms, $(500 - 500) / 2000 = 0$ sq. ft. garden\n",
        "    - House 3: $(7 - 2) / 5 = 1$ bedrooms, $(2300 - 500) / 2000 = 0.85$ sq. ft. garden\n",
        "\n",
        "    Now, the euclidean distance between the test instance and the training instances will be:\n",
        "\n",
        "    - Distance between house 1 and house 2: $\\sqrt{(0-0.2)^2 + (0.75-0)^2} = 0.77$\n",
        "    - Distance between house 1 and house 3: $\\sqrt{(0-1)^2 + (0.75-0.9)^2} = 1.11$\n",
        "\n",
        "    As you can see now, the distance between houses 1 and 2 is shorter than that between houses 1 and 3. The model will thus forecast that house 1 will cost about the same as house 2, according to the prediction. This is what is anticipated. This is what normalization does. It equalizes the scale of all features. This is important because it prevents the features with higher values from dominating the features with lower values.\n",
        "\n",
        "    Use the minimum and maximum values you found in the previous step to normalize the training and test sets.\n",
        "9. Now, you have to build a classifier to classify the type of wheat seed based on the measurements of the seed. Use the K-Nearest Neighbors algorithm to build the classifier. Use the Euclidean distance to find the nearest neighbors.\n",
        "\n",
        "10. Output the number of data points in the testing set and the number of correct predictions made by the classifier for each class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload the file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lULi8gyAml2T",
        "outputId": "2172b15c-85bd-4965-8989-b1eabda7645d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-965256c7-e35f-4f16-994b-3f12e7973971\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-965256c7-e35f-4f16-994b-3f12e7973971\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving seeds_dataset.txt to seeds_dataset (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "# Download the dataset from GitHub\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/geyser.csv\"  # Example URL - replace with actual dataset URL\n",
        "urllib.request.urlretrieve(url, \"seeds_dataset.txt\")\n",
        "\n",
        "# If the above URL doesn't work, try this alternative:\n",
        "try:\n",
        "    # The issue is likely with the delimiter.\n",
        "    # Try using whitespace as the delimiter instead of '\\t' if the data is space-separated.\n",
        "    dataset = np.genfromtxt('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt', delimiter=None) #Changed the delimiter to None since it's space separated\n",
        "except:\n",
        "    # If neither works, you'll need to upload the file manually\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    # Use whitespace as delimiter if the file is space separated\n",
        "    dataset = np.genfromtxt('seeds_dataset.txt', delimiter=None) #Changed the delimiter to None since it's space separated\n",
        "\n",
        "# Rest of your code...\n",
        "np.random.shuffle(dataset)\n",
        "\n",
        "# Split into features and labels\n",
        "features = dataset[:, 0:7]\n",
        "labels = dataset[:, 7]\n",
        "\n",
        "# Split into training and testing sets\n",
        "split_index = int(0.8 * len(dataset))\n",
        "train_features, test_features = np.split(features, [split_index])\n",
        "train_labels, test_labels = np.split(labels, [split_index])\n",
        "\n",
        "# Find min and max for each feature in training set\n",
        "min_vals = np.min(train_features, axis=0)\n",
        "max_vals = np.max(train_features, axis=0)\n",
        "ranges = max_vals - min_vals\n",
        "\n",
        "# Normalize training and test sets\n",
        "train_features_normalized = (train_features - min_vals) / ranges\n",
        "test_features_normalized = (test_features - min_vals) / ranges\n",
        "\n",
        "# K-Nearest Neighbors classifier\n",
        "def knn_classifier(train_features, train_labels, test_features, k=3):\n",
        "    predictions = []\n",
        "    for test_point in test_features:\n",
        "        # Calculate Euclidean distances\n",
        "        distances = np.sqrt(np.sum((train_features - test_point)**2, axis=1))\n",
        "\n",
        "        # Get indices of k nearest neighbors\n",
        "        nearest_indices = np.argpartition(distances, k)[:k]\n",
        "\n",
        "        # Get labels of nearest neighbors\n",
        "        nearest_labels = train_labels[nearest_indices]\n",
        "\n",
        "        # Predict the most common label\n",
        "        unique, counts = np.unique(nearest_labels, return_counts=True)\n",
        "        prediction = unique[np.argmax(counts)]\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Make predictions\n",
        "predictions = knn_classifier(train_features_normalized, train_labels, test_features_normalized)\n",
        "\n",
        "# Calculate accuracy for each class\n",
        "num_test_points = len(test_labels)\n",
        "class_labels = [1, 2, 3]\n",
        "class_names = ['Kama', 'Rosa', 'Canadian']\n",
        "\n",
        "print(f\"Number of data points in testing set: {num_test_points}\")\n",
        "\n",
        "for label, name in zip(class_labels, class_names):\n",
        "    mask = test_labels == label\n",
        "    correct = np.sum(predictions[mask] == test_labels[mask])\n",
        "    total = np.sum(mask)\n",
        "    print(f\"Class {name} ({label}): {correct} correct out of {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALCJQ-e5nXDx",
        "outputId": "8f853a8a-3a20-4a70-f254-d651fe2e3a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of data points in testing set: 42\n",
            "Class Kama (1): 13 correct out of 15\n",
            "Class Rosa (2): 9 correct out of 10\n",
            "Class Canadian (3): 16 correct out of 17\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b148fc9bfa8b60132af830e32e1690e4e023b803e92912df15b823b90141dda6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}